{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Embeddings"
   ],
   "metadata": {
    "id": "FT1FtZR-KNwJ"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KwWuWmjAKGbi",
    "ExecuteTime": {
     "end_time": "2025-08-11T20:19:18.959055Z",
     "start_time": "2025-08-11T20:19:16.859266Z"
    }
   },
   "source": "%pip install langchain-openai",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-openai in d:\\practice-rag\\.venv\\lib\\site-packages (0.3.29)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-openai) (0.3.74)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-openai) (1.99.7)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in d:\\practice-rag\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\practice-rag\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\practice-rag\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\practice-rag\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\practice-rag\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\practice-rag\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\practice-rag\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\practice-rag\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\practice-rag\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\practice-rag\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\practice-rag\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\practice-rag\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\practice-rag\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\practice-rag\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\practice-rag\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.86.0->langchain-openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ],
   "metadata": {
    "id": "sqd-HYFnKP4m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        'Hola!',\n",
    "        'Holas, cómo estás?',\n",
    "        'Cual es tu nombre?',\n",
    "        'Me llamo Daniel',\n",
    "        'Hola Daniel'\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "id": "F8K54LvPKRWM",
    "ExecuteTime": {
     "end_time": "2025-08-11T20:19:49.107911Z",
     "start_time": "2025-08-11T20:19:45.742173Z"
    }
   },
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOpenAIError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_openai\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m OpenAIEmbeddings\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m embeddings_model = \u001B[43mOpenAIEmbeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m embeddings = embeddings_model.embed_documents(\n\u001B[32m      5\u001B[39m     [\n\u001B[32m      6\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mHola!\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     11\u001B[39m     ]\n\u001B[32m     12\u001B[39m )\n",
      "    \u001B[31m[... skipping hidden 1 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\practice-rag\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:328\u001B[39m, in \u001B[36mOpenAIEmbeddings.validate_environment\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    326\u001B[39m         \u001B[38;5;28mself\u001B[39m.http_client = httpx.Client(proxy=\u001B[38;5;28mself\u001B[39m.openai_proxy)\n\u001B[32m    327\u001B[39m     sync_specific = {\u001B[33m\"\u001B[39m\u001B[33mhttp_client\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.http_client}\n\u001B[32m--> \u001B[39m\u001B[32m328\u001B[39m     \u001B[38;5;28mself\u001B[39m.client = \u001B[43mopenai\u001B[49m\u001B[43m.\u001B[49m\u001B[43mOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mclient_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43msync_specific\u001B[49m\u001B[43m)\u001B[49m.embeddings  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[32m    329\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.async_client:\n\u001B[32m    330\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.openai_proxy \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.http_async_client:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\practice-rag\\.venv\\Lib\\site-packages\\openai\\_client.py:130\u001B[39m, in \u001B[36mOpenAI.__init__\u001B[39m\u001B[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001B[39m\n\u001B[32m    128\u001B[39m     api_key = os.environ.get(\u001B[33m\"\u001B[39m\u001B[33mOPENAI_API_KEY\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m api_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m130\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m OpenAIError(\n\u001B[32m    131\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    132\u001B[39m     )\n\u001B[32m    133\u001B[39m \u001B[38;5;28mself\u001B[39m.api_key = api_key\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m organization \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mOpenAIError\u001B[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "embeddings"
   ],
   "metadata": {
    "id": "Mh8JzcwtKTBj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(embeddings[0])"
   ],
   "metadata": {
    "id": "s9i4ghJHKUlQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedded_query = embeddings_model.embed_query('Cual es el nombre mencionado en la conversación?')"
   ],
   "metadata": {
    "id": "dkDnO90DKWMb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedded_query"
   ],
   "metadata": {
    "id": "IpuGLkDzKXoq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "thmYPxzyKYxA"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
